{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import random\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# Train\n",
    "#-------------------------------------------------------------------------------------\n",
    "# validation auc score를 확인하기 위해 정의\n",
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels=y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score=auc(r,p) \n",
    "    return \"pr_auc\", score, True #name, score, no memory\n",
    "#-------------------------------------------------------------------------------------\n",
    "models     = []\n",
    "recalls    = []\n",
    "precisions = []\n",
    "auc_scores   = []\n",
    "threshold = 0.5\n",
    "# 파라미터 설정\n",
    "params =      {\n",
    "                'boosting_type' : 'gbdt', #dart gbdt\n",
    "                'objective'     : 'binary',\n",
    "                'metric'        : 'auc',\n",
    "                'seed': 1015\n",
    "                }\n",
    "#-------------------------------------------------------------------------------------\n",
    "# 5 Kfold cross validation\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_idx, val_idx in k_fold.split(train_X):\n",
    "\n",
    "    # split train, validation set\n",
    "    X = train_X[train_idx]\n",
    "    y = train_Y[train_idx]\n",
    "    valid_x = train_X[val_idx]\n",
    "    valid_y = train_Y[val_idx]\n",
    "\n",
    "    d_train= lgb.Dataset(X, y)\n",
    "    d_val  = lgb.Dataset(valid_x, valid_y)\n",
    "    \n",
    "    #run traning\n",
    "    model = lgb.train(\n",
    "                        params,\n",
    "                        train_set       = d_train,\n",
    "                        num_boost_round = 1000,\n",
    "                        valid_sets      = d_val,\n",
    "                        feval           = f_pr_auc,\n",
    "                        verbose_eval    = 20, \n",
    "                        early_stopping_rounds = 3\n",
    "                       )\n",
    "    \n",
    "    # cal valid prediction\n",
    "    valid_prob = model.predict(valid_x)\n",
    "    valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "    \n",
    "    # cal scores\n",
    "    recall    = recall_score(    valid_y, valid_pred)\n",
    "    precision = precision_score( valid_y, valid_pred)\n",
    "    auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "    # append scores\n",
    "    models.append(model)\n",
    "    recalls.append(recall)\n",
    "    precisions.append(precision)\n",
    "    auc_scores.append(auc_score)\n",
    "\n",
    "    print('==========================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
