{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = \"YOUR_DATASET\" # DATAFRAME\n",
    "\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = \"YOUR TRAINING INPUT\" # NUMPY\n",
    "train_Y = \"YOUR TRAINING LABEL\" # NUMPY\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_X = \"YOUR VALIDATION LABEL\" # NUMPY\n",
    "val_Y = \"YOUR VALIDATION LABEL\" # NUMPY\n",
    "\n",
    "print(val_X.shape)\n",
    "print(val_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling\n",
    "\n",
    "import random\n",
    "\n",
    "shuf = np.array([i for i in range(train_X.shape[0])])\n",
    "random.shuffle(shuf)\n",
    "\n",
    "train_X = train_X[shuf]\n",
    "train_Y = train_Y[shuf]\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "\n",
    "from tensorflow.config.experimental import list_physical_devices, set_memory_growth\n",
    "gpus = list_physical_devices('GPU')\n",
    "display(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    set_memory_growth(gpus[0], True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "    \n",
    "#######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import \"YOUR LAYER\"\n",
    "from tensorflow.keras.optimizers import \"YOUR OPTIMIZER\"\n",
    "from tensorflow.keras.metrics import \"YOUR METRIC\"\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "clear_session()\n",
    "\n",
    "# YOUR PARAMTERS\n",
    "#######################################################################################\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "def create_discriminator(input_dim):\n",
    "    model = Sequential(\"discriminator\")\n",
    "    \n",
    "    # MODEL\n",
    "    #######################################################################################\n",
    "\n",
    "    \n",
    "\n",
    "    #######################################################################################\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "discriminator = create_discriminator(train_X.shape[1:])\n",
    "\n",
    "discriminator.compile(loss='mse', optimizer=\"YOUR OPTIMIZER\", metrics=[\"YOUR METRIC\"])\n",
    "discriminator.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator\n",
    "\n",
    "from tensorflow.keras.layers import \n",
    "\n",
    "z_dim =\"YOUR LATENT VECTER DIM\"\n",
    "\n",
    "# YOUR PARAMTERS\n",
    "#######################################################################################\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "def create_generator(z_dim):\n",
    "    model = Sequential(name=\"generator\")\n",
    "    # MODEL\n",
    "    #######################################################################################\n",
    "\n",
    "    \n",
    "\n",
    "    #######################################################################################\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "generator = create_generator(z_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assemble\n",
    "\n",
    "model = Sequential(\"VanilaGAN\")\n",
    "model.add(generator)\n",
    "model.add(discriminator)\n",
    "model.compile(loss='YOUR LOSS', optimizer=\"YOUR OPTIMIZER\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "loss = []\n",
    "batch_size = \"YOUR BATCH SIZE\"\n",
    "interval = \"YOUR INTERVAL\"\n",
    "\n",
    "z_label_real = np.ones((batch_size, 1))\n",
    "z_label_fake = np.zeros((batch_size, 1))\n",
    "z = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "\n",
    "for i in tqdm(range(interval)):\n",
    "    idx = np.random.randint(0, train_X.shape[0], batch_size)\n",
    "    real_X = train_X[idx]\n",
    "    real_Y = train_Y[idx]\n",
    "    \n",
    "    d_loss_real = discriminator.train_on_batch(real_X, real_Y)\n",
    "    \n",
    "    z = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "    fake_x = generator.predict(z)\n",
    "    d_loss_fake = discriminator.train_on_batch(fake_x, z_label_fake)\n",
    "    \n",
    "    z = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "    g_loss = model.train_on_batch(z, z_label_real)\n",
    "    \n",
    "    if (i+1) % 1000 == 0:\n",
    "        d_loss_eval, d_AUC_eval = discriminator.evaluate(val_X, val_Y)\n",
    "        \n",
    "        print(i+1, \": g_loss: %.6f\" %(g_loss))\n",
    "        print(i+1, \": d_loss_real: %.6f\" %(d_loss_real[0]))\n",
    "        print(i+1, \": d_loss_fake: %.6f\" %(d_loss_fake[0]))\n",
    "        print(i+1, \": d_loss_eval: %.6f\" %(d_loss_eval))\n",
    "        print(i+1, \": d_AUC_eval: %.6f\" %(d_AUC_eval))\n",
    "\n",
    "        print(\"=\"*80)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
