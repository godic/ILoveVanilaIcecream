{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN-GP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sqlite3\n",
    "\n",
    "dataset =\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "def onehot_encoder(train_set, classes=\"AGCT\", is_train=True):\n",
    "    encoder = defaultdict(lambda: np.array([0]*len(classes)))\n",
    "    for i, _class in enumerate(classes):\n",
    "        tmp = np.zeros(len(classes))\n",
    "        tmp[i] = 1\n",
    "        encoder[_class] = tmp\n",
    "        \n",
    "    if is_train == True:\n",
    "        reverse = defaultdict(lambda: np.array([0]*len(classes)))\n",
    "        for i, _class in enumerate(\"TCGA\"):\n",
    "            tmp = np.zeros(len(classes))\n",
    "            tmp[i] = 1\n",
    "            reverse[_class] = tmp\n",
    "        \n",
    "    output = []\n",
    "    for record in tqdm(train_set):\n",
    "#         forward_pad = 9\n",
    "#         backward_pad = 9\n",
    "        \n",
    "        forward_pad = 0\n",
    "        backward_pad = 0\n",
    "        \n",
    "        encoded_record = []\n",
    "        for i in range(forward_pad):\n",
    "            encoded_record.append([.25, .25, .25, .25])\n",
    "            \n",
    "        for c in record.upper():\n",
    "            encoded_record.append(encoder[c])\n",
    "            \n",
    "        for i in range(backward_pad):\n",
    "            encoded_record.append([.25, .25, .25, .25])\n",
    "            \n",
    "        output.append(encoded_record)\n",
    "        \n",
    "        if is_train == True:\n",
    "            reversed_record = []\n",
    "            for i in range(forward_pad):\n",
    "                reversed_record.append([.25, .25, .25, .25])\n",
    "\n",
    "            for c in record.upper():\n",
    "                reversed_record.append(reverse[c])\n",
    "\n",
    "            for i in range(backward_pad):\n",
    "                reversed_record.append([.25, .25, .25, .25])\n",
    "\n",
    "            output.append(reversed_record)\n",
    "        \n",
    "    output = np.array(output)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = onehot_encoder(dataset.values, is_train=False)\n",
    "        \n",
    "train_X = onehot_encoder(dataset[seq_dataset[\"4R\"]>0].seq.values, is_train=False)\n",
    "importance = dataset[seq_dataset[\"4R\"]>0][\"4R\"].values\n",
    "\n",
    "# importance = importance / np.sum(importance)\n",
    "# importance = (importance + 1 - np.min(importance)) / np.std(importance)\n",
    "# importance = (importance+1 - np.min(importance))/ (np.max(importance) - np.min(importance))\n",
    "# importance = np.log(importance)\n",
    "# importance = importance ** .75 / np.sum(importance ** .75)\n",
    "importance = importance / np.mean(importance)\n",
    "\n",
    "print(\"std:\", np.std(importance))\n",
    "print(\"mean:\", np.mean(importance))\n",
    "\n",
    "print(train_X.shape)\n",
    "print(importance.shape)\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = pd.read_csv(\"../data/DRA009383/csv/SPR_DRA009383.csv\")\n",
    "display(validation_data)\n",
    "val_X = onehot_encoder(validation_data.Sequence.values, is_train=False)\n",
    "val_Y = np.array(validation_data[\"Positive/Negative\"].values)\n",
    "\n",
    "print(val_X.shape)\n",
    "print(val_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. GPU Diet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "from tensorflow.config.experimental import list_physical_devices, set_memory_growth\n",
    "gpus = list_physical_devices('GPU')\n",
    "display(gpus)\n",
    "if gpus:\n",
    "  try:\n",
    "    set_memory_growth(gpus[0], True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "    \n",
    "#######################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#critic\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LeakyReLU, Flatten, Dropout, Lambda, BatchNormalization, Input, MaxPooling1D, Add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "clear_session()\n",
    "\n",
    "# YOUR PARAMTERS\n",
    "#######################################################################################\n",
    "\n",
    "np.random.seed(1500)\n",
    "tf.random.set_seed(1500)\n",
    "\n",
    "kernel_size = 7\n",
    "pool_size = train_X.shape[1] - kernel_size + 1\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "def convolution_block(x, filters, size, strides):\n",
    "    \n",
    "    bn = BatchNormalization()(x)\n",
    "    l_relu = LeakyReLU()(bn)\n",
    "    conv1d = Conv1D(filters=filters, kernel_size=size, strides=strides, kernel_regularizer=regularizers.l1(1e-5),padding='same')(l_relu)\n",
    "    \n",
    "    return conv1d\n",
    "    \n",
    "def create_critic(input_dim):\n",
    "    \n",
    "    # MODEL\n",
    "    #######################################################################################\n",
    "    \n",
    "    inp = Input(shape=input_dim)\n",
    "    conv1 = Conv1D(filters=32, kernel_size=7, strides=1, kernel_regularizer=regularizers.l1(1e-5),padding='same')(inp)\n",
    "    convb1 = convolution_block(conv1, filters=64, size=7, strides=1)\n",
    "    convb2 = convolution_block(convb1, filters=64, size=7, strides=1)\n",
    "    convb2 = convolution_block(convb2, filters=32, size=7, strides=1)\n",
    "    add1 = Add()([conv1, convb2])\n",
    "    mp1 = MaxPooling1D(pool_size=input_dim[0])(add1)\n",
    "    \n",
    "    flatten = Flatten()(mp1)\n",
    "    \n",
    "    fc1 = Dense(32, kernel_regularizer=regularizers.l1(1e-5))(flatten)\n",
    "    l_relu1 = LeakyReLU()(fc1)\n",
    "    dropout1 = Dropout(rate=0.25)(l_relu1)\n",
    "    outp = Dense(1, kernel_regularizer=regularizers.l1(1e-5))(dropout1)\n",
    "    \n",
    "    model = Model(inp, outp)\n",
    "\n",
    "    #######################################################################################\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "critic = create_critic(train_X.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator\n",
    "from tensorflow.keras.layers import Conv1DTranspose, Reshape, Activation, UpSampling1D, ZeroPadding1D, Input, BatchNormalization, ReLU\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "z_dim = 100\n",
    "\n",
    "# YOUR PARAMTERS\n",
    "#######################################################################################\n",
    "\n",
    "design_len = 30\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "def create_generator(z_dim):\n",
    "    model = Sequential(name=\"generator\")\n",
    "    # MODEL\n",
    "    #######################################################################################\n",
    "    model.add(Input(z_dim))\n",
    "    model.add(Dense(64, kernel_regularizer=regularizers.l1(1e-5)))\n",
    "#     model.add(LeakyReLU())\n",
    "    model.add(Dense(32, kernel_regularizer=regularizers.l1(1e-5)))\n",
    "    model.add(Reshape((1, 32)))\n",
    "    model.add(Conv1DTranspose(filters=4, kernel_size=design_len, strides=1, kernel_regularizer=regularizers.l1(1e-5)))\n",
    "\n",
    "    model.add(Activation(\"softmax\"))\n",
    "#     model.add(Lambda(gumbel_softmax)\n",
    "    \n",
    "#     model.add(Lambda(lambda x: x-.25))\n",
    "#     model.add(ZeroPadding1D(padding=(9, 9)))\n",
    "#     model.add(Lambda(lambda x: x+.25))\n",
    "\n",
    "    #######################################################################################\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "generator = create_generator(z_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "critic_opt = Adam(learning_rate = 0.0001, beta_1=0, beta_2=0.9)\n",
    "generator_opt = Adam(learning_rate = 0.0001, beta_1=0, beta_2=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Write GEN FASTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "def train(dataset, importance, epoch):\n",
    "    for epoch in range(epoch):\n",
    "        g_loss = []\n",
    "        c_loss = []\n",
    "        \n",
    "        shuf = np.array([i for i in range(train_X.shape[0])])\n",
    "        random.shuffle(shuf)\n",
    "\n",
    "        dataset = dataset[shuf]\n",
    "        \n",
    "        for batch in tqdm(range(dataset.shape[0] // batch_size)):\n",
    "            real_X = dataset[batch * batch_size:(batch+1)*batch_size]\n",
    "            sample_weights = importance[batch * batch_size:(batch+1)*batch_size]\n",
    "            \n",
    "            loss_c = 0\n",
    "            for i in range(5):\n",
    "                loss_c += train_critic(real_X, sample_weights)\n",
    "#                 loss_c += train_critic(real_X, 1)\n",
    "            loss_g = train_generator(batch_size)\n",
    "        \n",
    "            g_loss.append(loss_g)\n",
    "            c_loss.append(loss_c / 5)\n",
    "        \n",
    "        # loss & plot\n",
    "        print ('epoch {}'.format(epoch + 1))\n",
    "        print (epoch+1, \":\", \"g_loss: {}\".format(sum(g_loss)/len(g_loss)))\n",
    "        print (epoch+1, \":\", \"c_loss: {}\".format(sum(c_loss)/len(c_loss)))\n",
    "         \n",
    "\n",
    "        show_plot()\n",
    "        write_gen_fasta(epoch)\n",
    "        print(\"=\"*80)\n",
    "    \n",
    "    retun "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(train_X, importance, 100)\n",
    "# train(train_X, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
